Explica√ß√£o Detalhada do Modelo Atual

Resumo: O modelo de IA que voc√™ treinou est√° classificado not√≠cias em duas categorias: 
"Economia" e "Governo". O treinamento foi baseado em dados que associam not√≠cias espec√≠ficas 
com uma dessas duas categorias. Portanto, o modelo aprendeu a identificar padr√µes nas not√≠cias 
que indicam se elas s√£o sobre economia ou governo.

Exemplo:

    Entrada: Uma not√≠cia, como "Bolsa de valores em alta".
    Processo: O modelo analisa o texto da not√≠cia, procurando padr√µes ou palavras que indicam se a not√≠cia √© sobre economia ou governo.
    Sa√≠da: O modelo classifica a not√≠cia como "Economia" (valor 1) ou "Governo" (valor 0).

codigo abaixo:

"""import os
import json
import pandas as pd
from dagster import AssetKey, get_dagster_logger, asset
from crawler_noticia.governo.governo.spiders.noticia import G1Spider
from crawler_noticia.economia.economia.spiders.noticia import NoticiasSpider
from scrapy.crawler import CrawlerProcess
from db_mongo.conexao_mongo import salvar_no_mongo, conectar_mongo
import matplotlib.pyplot as plt

# Fun√ß√£o para rodar o spider e salvar os dados no MongoDB
def run_spider(spider, output_file, collection_name):
    logger = get_dagster_logger()
    if os.path.exists(output_file):
        os.remove(output_file)
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    process = CrawlerProcess(settings={
        "FEED_FORMAT": "json",
        "FEED_URI": output_file
    })

    process.crawl(spider)
    process.start()

    if os.path.exists(output_file):
        with open(output_file, "r", encoding='utf-8') as f:
            data = json.load(f)
            salvar_no_mongo(data, collection_name)
            logger.info(f"Data for {collection_name} saved to MongoDB")
# Assets para os crawlers
@asset 
def crawler_economia() -> None:
    run_spider(NoticiasSpider, "data/economia.json", "economia")

@asset 
def crawler_governo() -> None:
    run_spider(G1Spider, "data/governo.json", "governo")

# Fun√ß√£o para tratar os dados
def tratar_dados(colecao_nome: str) -> pd.DataFrame:
    db = conectar_mongo()
    colecao = db[colecao_nome]
    data = pd.DataFrame(list(colecao.find()))
    data = data.drop(columns=['_id'], errors='ignore')

    # Garantir que todos os dados sejam strings ou num√©ricos e converter colunas de texto em n√∫meros
    for col in data.columns:
        data[col] = data[col].apply(lambda x: str(x) if isinstance(x, (dict, list)) else x)
        if data[col].dtype == 'object':
            try:
                data[col] = pd.to_numeric(data[col], errors='coerce')
            except:
                data[col] = data[col].astype('category').cat.codes

    # Adiciona a coluna 'target' se n√£o existir
    if 'target' not in data.columns:
        data['target'] = 0  # ou qualquer l√≥gica que voc√™ tenha para definir 'target'
    
    return data

# Assets para tratamento dos dados
@asset 
def tratar_dados_economia() -> pd.DataFrame:
    return tratar_dados('economia')

@asset 
def tratar_dados_governo() -> pd.DataFrame:
    return tratar_dados('governo')

# Fun√ß√£o para gerar gr√°ficos de acur√°cia
def gerar_grafico_acuracia(nome_modelo, accuracy):
    os.makedirs('resultados', exist_ok=True)
    plt.figure()
    plt.bar([nome_modelo], [accuracy])
    plt.ylabel('Acur√°cia')
    plt.title(f'Acur√°cia do modelo {nome_modelo}')
    plt.savefig(f'resultados/{nome_modelo}_acuracia.png')

# Assets para treinamento e teste da IA
@asset 
def treinar_ia_economia(tratar_dados_economia: pd.DataFrame) -> None:
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score

    # Verifica se h√° dados suficientes
    if len(tratar_dados_economia) < 2:
        raise ValueError("Dados insuficientes para treinamento e teste")

    # Prepare os dados de treino e teste
    X = tratar_dados_economia.drop(columns=['target'])
    y = tratar_dados_economia['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Treine o modelo
    modelo = RandomForestClassifier()
    modelo.fit(X_train, y_train)

    # Teste o modelo
    y_pred = modelo.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    logger = get_dagster_logger()
    logger.info(f"Modelo de IA treinado com acur√°cia: {accuracy}")

    # Gerar gr√°fico de acur√°cia
    gerar_grafico_acuracia("Economia", accuracy)

@asset 
def treinar_ia_governo(tratar_dados_governo: pd.DataFrame) -> None:
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score

    # Verifica se h√° dados suficientes
    if len(tratar_dados_governo) < 2:
        raise ValueError("Dados insuficientes para treinamento e teste")

    # Prepare os dados de treino e teste
    X = tratar_dados_governo.drop(columns=['target'])
    y = tratar_dados_governo['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Treine o modelo
    modelo = RandomForestClassifier()
    modelo.fit(X_train, y_train)

    # Teste o modelo
    y_pred = modelo.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    logger = get_dagster_logger()
    logger.info(f"Modelo de IA treinado com acur√°cia: {accuracy}")

    # Gerar gr√°fico de acur√°cia
    gerar_grafico_acuracia("Governo", accuracy)
"""


Como Melhorar e Tornar o Projeto Mais √ötil

Se voc√™ deseja que o projeto tenha uma aplica√ß√£o mais pr√°tica e √∫til, podemos pensar em algumas melhorias e novas funcionalidades. Aqui est√£o algumas sugest√µes:

    An√°lise de Sentimentos:
        Objetivo: Determinar se uma not√≠cia √© positiva, negativa ou neutra.
        Utilidade: Empresas podem usar isso para entender a percep√ß√£o p√∫blica sobre suas a√ß√µes, pol√≠ticas ou eventos econ√¥micos.

    Previs√£o de Tend√™ncias Econ√¥micas:
        Objetivo: Analisar not√≠cias econ√¥micas para prever tend√™ncias futuras, como crescimento do PIB, infla√ß√£o, etc.
        Utilidade: Economistas e analistas financeiros podem usar isso para tomar decis√µes informadas.

    Detec√ß√£o de Fake News:
        Objetivo: Identificar not√≠cias falsas ou potencialmente enganosas.
        Utilidade: Ajudar plataformas de m√≠dia social e leitores a identificar e combater a desinforma√ß√£o.

    Classifica√ß√£o Multi-Classe:
        Objetivo: Expandir as categorias para incluir mais t√≥picos, como "Sa√∫de", "Tecnologia", "Esportes", etc.
        Utilidade: Prover uma an√°lise mais detalhada e diversificada de not√≠cias.

Agora o seu projeto n√£o apenas classifica not√≠cias como "Economia" ou "Governo", mas tamb√©m analisa os sentimentos expressos nas not√≠cias. 
A an√°lise de sentimentos pode ajudar a entender melhor a percep√ß√£o p√∫blica e a emo√ß√£o transmitida pelas not√≠cias. Essa informa√ß√£o adicional 
pode ser √∫til para empresas, governos e outras organiza√ß√µes na tomada de decis√µes informadas.


Interpreta√ß√£o do Resultado

    Score de Sentimento:
        O score['compound'] varia de -1 (muito negativo) a 1 (muito positivo).
        Um valor pr√≥ximo de 0 indica um sentimento neutro.

Texto: A economia brasileira cresceu 5% no √∫ltimo trimestre.
Sentimento: 0.6124

Texto: O governo anunciou uma nova reforma pol√≠tica.
Sentimento: 0.4404

Texto: A bolsa de valores est√° em alta.
Sentimento: 0.6369

Texto: Uma nova lei foi aprovada pelo governo.
Sentimento: 0.2023



Baseando-se na sua explica√ß√£o e nas informa√ß√µes fornecidas, vamos detalhar a interpreta√ß√£o dos resultados da an√°lise de sentimentos das not√≠cias:

    Classifica√ß√£o de Sentimentos:
        Positivo: Valores de sentimento (score) acima de 0 indicam um sentimento positivo.
        Negativo: Valores de sentimento (score) abaixo de 0 indicam um sentimento negativo.
        Neutro: Valores de sentimento (score) pr√≥ximos de 0 indicam um sentimento neutro.

    Pontua√ß√£o de Sentimento (Score):
        A pontua√ß√£o de sentimento varia de -1 (muito negativo) a 1 (muito positivo).
        Um valor pr√≥ximo de 0 indica um sentimento neutro.

    Interpreta√ß√£o dos Resultados:
        Not√≠cia 1:
            T√≠tulo: 'Ismail Haniyeh: quem √© o principal chefe do Hamas, morto no Ir√£'
            Sentimento: 0.1531 (Positivo)
            Interpreta√ß√£o: Esta not√≠cia, apesar de tratar de um tema sens√≠vel, foi interpretada como ligeiramente positiva, possivelmente devido √† forma como o texto foi escrito.
        Not√≠cia 2:
            T√≠tulo: 'Elei√ß√£o na Venezuela n√£o atende padr√£o de integridade e n√£o pode ser considerada democr√°tica, diz Centro Carter'
            Sentimento: -0.4404 (Negativo)
            Interpreta√ß√£o: Esta not√≠cia foi interpretada como negativa, refletindo o tom cr√≠tico sobre a elei√ß√£o na Venezuela.
        Not√≠cia 3:
            T√≠tulo: 'Rebeca Andrade √© alvo do golpe do "falso familiar" no WhatsApp; veja como se proteger'
            Sentimento: -0.7644 (Negativo)
            Interpreta√ß√£o: Esta not√≠cia foi interpretada como muito negativa, refletindo o impacto negativo do golpe descrito.
        Not√≠cia 4:
            T√≠tulo: 'N√∫mero de mortos em protestos na Venezuela sobe'
            Sentimento: 0.0000 (Neutro)
            Interpreta√ß√£o: Esta not√≠cia foi interpretada como neutra, possivelmente por apresentar fatos sem uma conota√ß√£o emocional forte.
        Not√≠cia 5:
            T√≠tulo: 'Tens√£o dispara no Oriente M√©dio ap√≥s o assassinato do l√≠der do Hamas'
            Sentimento: 0.0000 (Neutro)
            Interpreta√ß√£o: Esta not√≠cia tamb√©m foi interpretada como neutra, provavelmente devido √† apresenta√ß√£o dos eventos de maneira factual.

Benef√≠cios da An√°lise de Sentimentos:

A an√°lise de sentimentos proporciona insights valiosos sobre a percep√ß√£o p√∫blica e a emo√ß√£o transmitida pelas not√≠cias. Isso pode ser extremamente √∫til para:

    Empresas: Avaliar a percep√ß√£o de suas a√ß√µes e campanhas, ajustar estrat√©gias de marketing e comunica√ß√£o.
    Governos: Compreender a opini√£o p√∫blica sobre pol√≠ticas e eventos, e ajustar suas comunica√ß√µes e pol√≠ticas em resposta.
    Organiza√ß√µes: Analisar o impacto das not√≠cias em diferentes √°reas, identificar tend√™ncias e tomar decis√µes informadas.

Exemplo de Uso Pr√°tico:

Vamos considerar a interpreta√ß√£o dos sentimentos em alguns textos espec√≠ficos:

    Texto: "A economia brasileira cresceu 5% no √∫ltimo trimestre."
        Sentimento: 0.6124 (Positivo)
        Interpreta√ß√£o: Este texto tem um sentimento positivo, indicando uma percep√ß√£o favor√°vel sobre o crescimento econ√¥mico.

    Texto: "O governo anunciou uma nova reforma pol√≠tica."
        Sentimento: 0.4404 (Positivo)
        Interpreta√ß√£o: Este texto √© percebido de forma positiva, sugerindo que a reforma pol√≠tica foi vista como uma a√ß√£o ben√©fica.

    Texto: "A bolsa de valores est√° em alta."
        Sentimento: 0.6369 (Positivo)
        Interpreta√ß√£o: Este texto tem um sentimento positivo, indicando uma percep√ß√£o favor√°vel sobre o desempenho da bolsa de valores.

    Texto: "Uma nova lei foi aprovada pelo governo."
        Sentimento: 0.2023 (Positivo)
        Interpreta√ß√£o: Este texto √© percebido de forma ligeiramente positiva, sugerindo que a aprova√ß√£o da nova lei √© vista como uma a√ß√£o ben√©fica, mas com menos intensidade emocional.

Conclus√£o

A an√°lise de sentimentos pode complementar a classifica√ß√£o das not√≠cias por categoria, fornecendo uma camada adicional de entendimento sobre como as not√≠cias s√£o percebidas. Isso √© particularmente √∫til para an√°lise de tend√™ncias e tomadas de decis√£o estrat√©gicas.




Sim, o algoritmo que voc√™ descreveu utiliza aprendizado de m√°quina, especificamente a t√©cnica de Random Forest, para treinar e testar modelos preditivos.
Explica√ß√£o do Algoritmo:

    Coleta de Dados com Scrapy:
        O c√≥digo come√ßa coletando dados de not√≠cias usando spiders Scrapy (G1Spider e NoticiasSpider) e salvando-os em arquivos JSON.

    Armazenamento no MongoDB:
        Os dados coletados s√£o armazenados no MongoDB para facilitar o acesso e a manipula√ß√£o.

    Tratamento de Dados:
        Os dados s√£o carregados do MongoDB e tratados. Isso inclui a remo√ß√£o de colunas desnecess√°rias, a extra√ß√£o de texto de campos de dicion√°rio, a adi√ß√£o de uma coluna target, e a an√°lise de sentimentos usando a biblioteca VaderSentiment para adicionar colunas de sentimento e classifica√ß√£o de sentimento.

    Treinamento e Teste da IA:
        O c√≥digo usa a biblioteca Scikit-learn para treinar um modelo de Random Forest com os dados tratados. O processo inclui:
            Divis√£o dos dados em conjuntos de treino e teste.
            Treinamento do modelo com os dados de treino.
            Teste do modelo com os dados de teste.
            Avalia√ß√£o da acur√°cia do modelo.

    Gera√ß√£o de Gr√°ficos:
        Ap√≥s o treinamento e a avalia√ß√£o do modelo, o c√≥digo gera gr√°ficos para visualizar a acur√°cia do modelo e a distribui√ß√£o dos sentimentos das not√≠cias.

Componentes do Algoritmo:

    Random Forest Classifier:
        √â um algoritmo de aprendizado de m√°quina do tipo ensemble learning, usado para tarefas de classifica√ß√£o e regress√£o. Ele cria m√∫ltiplas √°rvores de decis√£o durante o treinamento e outputa a classe que √© o modo das classes (classifica√ß√£o) ou a m√©dia das previs√µes (regress√£o) das √°rvores individuais.
    An√°lise de Sentimentos com VaderSentiment:
        A biblioteca VaderSentiment √© usada para realizar a an√°lise de sentimentos no texto das not√≠cias. Ela atribui uma pontua√ß√£o de sentimento (compound) que varia de -1 (muito negativo) a 1 (muito positivo).



Conclus√£o

Esse c√≥digo combina web scraping, an√°lise de sentimentos e aprendizado de m√°quina para coletar, 
processar e analisar dados de not√≠cias, fornecendo insights √∫teis sobre o sentimento p√∫blico e a 
percep√ß√£o das not√≠cias. O uso de Random Forest para o treinamento do modelo de IA ajuda a criar previs√µes 
robustas e precisas, aproveitando a capacidade desse algoritmo de lidar bem com dados heterog√™neos e evitar overfitting.

Sim, o projeto descrito integra aspectos de RPA (Automa√ß√£o de Processos Rob√≥ticos), Engenharia de Dados e Ci√™ncia de Dados, cada um desempenhando um papel crucial no fluxo completo do projeto. Aqui est√° como cada √°rea est√° representada:
1. RPA (Automa√ß√£o de Processos Rob√≥ticos)

RPA √© utilizado aqui para automatizar a coleta de dados de sites de not√≠cias. Os crawlers, implementados usando Scrapy, fazem parte da automa√ß√£o de processos, onde tarefas repetitivas de coleta de dados s√£o realizadas de forma autom√°tica. Aqui est√£o os componentes de RPA no projeto:

    Scrapy spiders (G1Spider e NoticiasSpider): Automatizam a coleta de not√≠cias de diferentes sites.
    run_spider: Fun√ß√£o que executa os spiders e salva os dados coletados em arquivos JSON e posteriormente no MongoDB.

2. Engenharia de Dados

A Engenharia de Dados envolve a movimenta√ß√£o, transforma√ß√£o e armazenamento dos dados coletados, preparando-os para a an√°lise posterior. No projeto, isso inclui:

    Conex√£o e armazenamento no MongoDB (salvar_no_mongo, conectar_mongo): As not√≠cias coletadas s√£o armazenadas em um banco de dados NoSQL para f√°cil acesso e consulta.
    Tratamento de dados (tratar_dados, tratar_dados_economia, tratar_dados_governo): Fun√ß√µes que limpam e processam os dados brutos coletados, preparando-os para an√°lise.

3. Ci√™ncia de Dados

A Ci√™ncia de Dados √© aplicada no projeto para analisar os dados processados e extrair insights, incluindo a an√°lise de sentimentos e a cria√ß√£o de modelos preditivos. Os componentes incluem:

    An√°lise de Sentimentos: Utiliza a biblioteca vaderSentiment para analisar o sentimento das not√≠cias.
    Treinamento de Modelos de IA (treinar_ia_economia, treinar_ia_governo): Usa RandomForestClassifier do sklearn para treinar modelos preditivos com base nos dados processados.
    Visualiza√ß√£o de Dados (gerar_grafico_acuracia, gerar_grafico_sentimentos): Fun√ß√µes que geram gr√°ficos de precis√£o e de distribui√ß√£o de sentimentos para visualiza√ß√£o dos resultados da an√°lise.

Fluxo Geral do Projeto

    Coleta de Dados (RPA):
        Os spiders automatizam a coleta de not√≠cias de diferentes fontes.
        Os dados coletados s√£o salvos em arquivos JSON e depois no MongoDB.

    Armazenamento e Processamento de Dados (Engenharia de Dados):
        Os dados s√£o armazenados no MongoDB.
        Fun√ß√µes de tratamento processam e limpam os dados, preparando-os para an√°lise.

    An√°lise e Modelagem (Ci√™ncia de Dados):
        Realiza-se a an√°lise de sentimentos nas not√≠cias.
        Treinamento de modelos preditivos usando RandomForestClassifier.



Resumo

    RPA: Automa√ß√£o da coleta de dados utilizando Scrapy.
    Engenharia de Dados: Armazenamento no MongoDB, limpeza e prepara√ß√£o dos dados.
    Ci√™ncia de Dados: An√°lise de sentimentos e cria√ß√£o de modelos preditivos com visualiza√ß√£o de resultados.

Este projeto √© uma integra√ß√£o poderosa que demonstra o fluxo completo de coleta de dados, processamento e an√°lise para 
fornecer insights valiosos a partir de dados de not√≠cias.

















Faz um tempo que n√£o posto no linkedin, mas estive focado na reta final da faculdade e no meu TCC. 
Hoje, quero compartilhar um projeto simples que desenvolvi recentemente. 

üë®‚Äçüè´Explica√ß√£o do Projeto

Este projeto √© uma aplica√ß√£o de an√°lise de not√≠cias com foco em dois t√≥picos principais: Economia e Governo. Utilizamos v√°rias ferramentas 
e t√©cnicas para automatizar(RPA) a coleta de dados, processamento e an√°lise de sentimentos, al√©m de treinar um modelo de IA para classificar as not√≠cias.

üìöEstrutura do Projeto

    Coleta de Dados: Utilizamos Scrapy, uma ferramenta de scraping, para extrair not√≠cias de sites de 
    Economia e Governo. Os dados coletados s√£o armazenados em arquivos JSON e posteriormente salvos em uma base de dados MongoDB.

    Tratamento de Dados: Ap√≥s a coleta, os dados s√£o processados para extrair texto relevante e realizar uma an√°lise de sentimentos utilizando 
    a biblioteca vaderSentiment. Os resultados s√£o classificados como "positivo", "negativo" ou "neutro".

    Armazenamento: Os dados brutos e tratados s√£o armazenados em cole√ß√µes no MongoDB, permitindo f√°cil acesso e consulta para an√°lises futuras.

    Treinamento de IA: Utilizamos o RandomForestClassifier para treinar um modelo de IA com os dados tratados, dividindo-os em conjuntos 
    de treino e teste. A acur√°cia do modelo √© avaliada e registrada.

    Gera√ß√£o de Gr√°ficos: Geramos gr√°ficos de acur√°cia do modelo e de sentimentos das not√≠cias para visualiza√ß√£o dos resultados.

üõ†Ô∏èFerramentas Utilizadas

    Dagster: Usado para orquestrar o fluxo de trabalho desde a coleta de dados at√© a gera√ß√£o dos resultados finais.
    Scrapy: Para automa√ß√£o da coleta de dados de not√≠cias.
    MongoDB: Para armazenamento e consulta de dados.
    VaderSentiment: Para an√°lise de sentimentos dos textos coletados.
    Scikit-learn: Para cria√ß√£o e avalia√ß√£o de modelos de IA.

üìùConclus√£o

Este projeto integra automa√ß√£o, engenharia de dados e ci√™ncia de dados para oferecer insights 
valiosos sobre a percep√ß√£o p√∫blica em rela√ß√£o a t√≥picos de Economia e Governo. √â um exemplo de 
como essas √°reas podem ser combinadas para criar solu√ß√µes anal√≠ticas eficazes.

#RPA #EngenhariaDeDados #Ci√™nciaDeDados #MachineLearning #IA #Automa√ß√£o #DataScience 



Faz algum tempo que n√£o posto nada aqui no linkedin, mas estive focado na reta final da faculdade e no meu TCC. 
Hoje, quero compartilhar um projeto simples que desenvolvi recentemente. 

Explica√ß√£o do Projeto

Este projeto √© uma aplica√ß√£o de an√°lise de not√≠cias com foco em dois t√≥picos principais: Economia e Governo. Utilizei v√°rias ferramentas 
e t√©cnicas para automatizar(RPA) a coleta de dados, processamento e an√°lise de sentimentos, al√©m de treinar um modelo de IA para classificar as not√≠cias.

Estrutura do Projeto

    Coleta de Dados: Utilizei Scrapy, uma ferramenta de scraping, para extrair not√≠cias de sites de 
    Economia e Governo. Os dados coletados s√£o armazenados em arquivos JSON e posteriormente salvos em uma base de dados MongoDB.

    Tratamento de Dados: Ap√≥s a coleta, os dados s√£o processados para extrair texto relevante e realizar uma an√°lise de sentimentos utilizando 
    a biblioteca vaderSentiment. Os resultados s√£o classificados como "positivo", "negativo" ou "neutro".

    Armazenamento: Os dados brutos e tratados s√£o armazenados em cole√ß√µes no MongoDB, permitindo f√°cil acesso e consulta para an√°lises futuras.

    Treinamento de IA: Utilizei o RandomForestClassifier para treinar um modelo de IA com os dados tratados, dividindo-os em conjuntos 
    de treino e teste. A acur√°cia do modelo √© avaliada e registrada.

    Gera√ß√£o de Gr√°ficos: Gerado gr√°ficos de acur√°cia do modelo e de sentimentos das not√≠cias para visualiza√ß√£o dos resultados.

Ferramentas Utilizadas

    Dagster: Usado para orquestrar o fluxo de trabalho desde a coleta de dados at√© a gera√ß√£o dos resultados finais.
    Scrapy: Para automa√ß√£o da coleta de dados de not√≠cias.
    MongoDB: Para armazenamento e consulta de dados.
    VaderSentiment: Para an√°lise de sentimentos dos textos coletados.
    Scikit-learn: Para cria√ß√£o e avalia√ß√£o de modelos de IA.

Conclus√£o

Este projeto integra automa√ß√£o, engenharia de dados e ci√™ncia de dados para oferecer insights 
valiosos sobre a percep√ß√£o p√∫blica em rela√ß√£o a t√≥picos de Economia e Governo. √â um exemplo de 
como essas √°reas podem ser combinadas para criar solu√ß√µes anal√≠ticas eficazes.

#RPA #EngenhariaDeDados #Ci√™nciaDeDados #MachineLearning #IA #Automa√ß√£o #DataScience 